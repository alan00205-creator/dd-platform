import streamlit as st
import pandas as pd
import time
import feedparser  # pip install feedparser
from io import BytesIO
from urllib.parse import quote

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="ç¶²è·¯æ–°èè³‡æ–™æª¢ç´¢", page_icon="ğŸŒ", layout="wide")

# ==========================================
# æ ¸å¿ƒå‡½æ•¸ 1ï¼šGoogle News RSS çˆ¬èŸ² (è¨­å®šä¸Šé™ç‚º 100)
# ==========================================
def get_search_results(keyword, max_results=100):
    results = []
    
    # URL Encode é—œéµå­—
    encoded_keyword = quote(keyword)
    
    # Google News RSS é€£çµ (å°ç£ç¹é«”)
    rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    
    try:
        # è§£æ RSS
        feed = feedparser.parse(rss_url)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å…§å®¹
        if feed.entries:
            # ä¾åºè®€å–æ–‡ç« ï¼Œæœ€å¤šå– max_results (é è¨­100)
            for entry in feed.entries[:max_results]:
                # è™•ç†æ™‚é–“æ ¼å¼
                published_time = entry.get('published', 'æœªçŸ¥æ—¥æœŸ')
                try:
                    dt_obj = pd.to_datetime(published_time)
                    display_date = dt_obj.strftime('%Y-%m-%d %H:%M')
                except:
                    display_date = published_time

                results.append({
                    "æ—¥æœŸ": display_date,
                    "æŸ¥è©¢ç›®æ¨™": keyword,
                    "æ¨™é¡Œ": entry.get('title'),
                    "é€£çµ": entry.get('link'),
                    "ä¾†æº": entry.get('source', {}).get('title', 'Google News'),
                    "æ‘˜è¦": "é»æ“Šé€£çµæŸ¥çœ‹å®Œæ•´æ–°è..." 
                })
        else:
            pass

    except Exception as e:
        results.append({
            "æ—¥æœŸ": "",
            "æŸ¥è©¢ç›®æ¨™": keyword,
            "æ¨™é¡Œ": "âŒ æŸ¥è©¢ç™¼ç”ŸéŒ¯èª¤",
            "é€£çµ": "",
            "ä¾†æº": "",
            "æ‘˜è¦": str(e)
        })
    
    return results

# ==========================================
# æ ¸å¿ƒå‡½æ•¸ 2ï¼šExcel åŒ¯å‡ºè™•ç†
# ==========================================
def convert_df_to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='æ–°èæœå°‹çµæœ')
        
        worksheet = writer.sheets['æ–°èæœå°‹çµæœ']
        for i, col in enumerate(df.columns):
            max_len = max(df[col].astype(str).map(len).max(), len(col)) + 2
            final_len = min(max_len, 60) 
            worksheet.set_column(i, i, final_len)
            
    processed_data = output.getvalue()
    return processed_data

# ==========================================
# ä¸»ä»‹é¢ UI
# ==========================================

st.title("ğŸŒ ç¶²è·¯æ–°èè³‡æ–™æª¢ç´¢")
st.markdown("ä½¿ç”¨ **Google News RSS** ä¾†æºï¼Œå³æ™‚å–å¾—ç„¡å»£å‘Šã€æŒ‰æ™‚é–“æ’åºçš„ç´”æ·¨æ–°èã€‚")

# --- å´é‚Šæ¬„å·²ç§»é™¤è¼”åŠ©è¨­å®š ---

# --- å»ºç«‹é ç±¤ ---
tab1, tab2 = st.tabs(["ğŸ” å–®ä¸€å…¬å¸é€ŸæŸ¥", "ğŸ“‚ æ‰¹æ¬¡åå–®æŸ¥è©¢"])

# --------------------------
# Tab 1: å–®ä¸€æŸ¥è©¢
# --------------------------
with tab1:
    col1, col2 = st.columns([3, 1])
    with col1:
        target_company = st.text_input("è¼¸å…¥å…¬å¸åç¨±", value="å°ç©é›»")
    with col2:
        st.write("") 
        st.write("") 
        search_btn = st.button("é–‹å§‹æœå°‹", use_container_width=True)

    if search_btn and target_company:
        full_query = target_company.strip()
        
        with st.spinner(f"æ­£åœ¨æŠ“å– `{full_query}` çš„æ–°è (æœ€å¤šé¡¯ç¤º 50 ç­†)..."):
            # è¨­å®š max_results=100
            results = get_search_results(full_query, max_results=50)
            
            if results and "âŒ" not in results[0]['æ¨™é¡Œ']:
                st.success(f"æ‰¾åˆ° {len(results)} å‰‡æ–°è")
                
                for item in results:
                    with st.container():
                        st.markdown(f"### [{item['æ¨™é¡Œ']}]({item['é€£çµ']})")
                        col_info1, col_info2 = st.columns([1, 5])
                        with col_info1:
                            st.caption(f"ğŸ“… {item['æ—¥æœŸ']}")
                        with col_info2:
                            st.caption(f"ğŸ“° {item['ä¾†æº']}")
                        st.divider()
            else:
                st.warning("æ‰¾ä¸åˆ°ç›¸é—œæ–°èï¼Œæˆ–é€£ç·šç•°å¸¸ã€‚")

# --------------------------
# Tab 2: æ‰¹æ¬¡æŸ¥è©¢
# --------------------------
with tab2:
    st.markdown("### æ‰¹æ¬¡æ–°èæª¢ç´¢")
    st.info("ğŸ’¡ é€é RSS æŠ€è¡“ï¼Œæ‰¹æ¬¡æŸ¥è©¢æ›´åŠ ç©©å®šä¸”å¿«é€Ÿã€‚")
    
    input_method = st.radio("è³‡æ–™ä¾†æº", ["è‡ªè¡Œè¼¸å…¥", "ä¸Šå‚³ Excel/CSV"], horizontal=True)
    
    company_list = []

    if input_method == "è‡ªè¡Œè¼¸å…¥":
        raw_text = st.text_area("è¼¸å…¥å…¬å¸åç¨± (æŒ‰ Enter æ›è¡Œ)", "å°ç©é›»\né´»æµ·\nè¯ç™¼ç§‘")
        if raw_text:
            company_list = [x.strip() for x in raw_text.split('\n') if x.strip()]

    elif input_method == "ä¸Šå‚³ Excel/CSV":
        uploaded_file = st.file_uploader("ä¸Šå‚³æª”æ¡ˆ", type=['xlsx', 'csv'])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df_upload = pd.read_csv(uploaded_file)
                else:
                    df_upload = pd.read_excel(uploaded_file)
                col_name = st.selectbox("è«‹é¸æ“‡åŒ…å«å…¬å¸åç¨±çš„æ¬„ä½", df_upload.columns)
                company_list = df_upload[col_name].dropna().astype(str).tolist()
                st.success(f"å·²è®€å– {len(company_list)} ç­†å…¬å¸è³‡æ–™ã€‚")
            except Exception as e:
                st.error("æª”æ¡ˆè®€å–å¤±æ•—ã€‚")

    if st.button("ğŸš€ åŸ·è¡Œæ‰¹æ¬¡æ–°èæª¢ç´¢") and company_list:
        progress_bar = st.progress(0)
        status_text = st.empty()
        all_results = []
        total = len(company_list)
        
        for i, company in enumerate(company_list):
            status_text.text(f"æ­£åœ¨æŠ“å– ({i+1}/{total}): {company} ...")
            
            query = company.strip()
            # æ‰¹æ¬¡æŸ¥è©¢æ¯é–“å…¬å¸ä¸Šé™è¨­ç‚º 20 ç­† (é¿å… Excel å¤ªå¤§)ï¼Œè‹¥éœ€æ›´å¤šå¯è‡ªè¡Œæ”¹ç‚º 100
            res = get_search_results(query, max_results=30)
            all_results.extend(res)
            
            progress_bar.progress((i + 1) / total)
            time.sleep(0.5) 
        
        status_text.text("âœ… æª¢ç´¢å®Œæˆï¼")
        progress_bar.progress(100)
        
        if all_results:
            final_df = pd.DataFrame(all_results)
            st.dataframe(final_df)
            excel_data = convert_df_to_excel(final_df)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰æ–°èå½™æ•´å ±å‘Š",
                data=excel_data,
                file_name=f"DD_News_RSS_{int(time.time())}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
